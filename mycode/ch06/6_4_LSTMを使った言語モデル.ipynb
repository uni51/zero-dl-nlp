{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6章 ゲート付きRNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 LSTMを使った言語モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.time_layers import *\n",
    "from common.base_model import BaseModel\n",
    "\n",
    "\n",
    "class Rnnlm(BaseModel):\n",
    "    def __init__(self, vocab_size=10000, wordvec_size=100, hidden_size=100):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        # 重みの初期化\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b = np.zeros(4 * H).astype('f')\n",
    "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        # レイヤの生成\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=True),\n",
    "            TimeAffine(affine_W, affine_b)\n",
    "        ]\n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.lstm_layer = self.layers[1]\n",
    "\n",
    "        # すべての重みと勾配をリストにまとめる\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    def predict(self, xs):\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        return xs\n",
    "\n",
    "    def forward(self, xs, ts):\n",
    "        score = self.predict(xs)\n",
    "        loss = self.loss_layer.forward(score, ts)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.lstm_layer.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PTBデータセットの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ptb.test.txt ... \n",
      "Done\n",
      "| epoch 1 |  iter 1 / 1327 | time 0[s] | perplexity 10002.40\n",
      "| epoch 1 |  iter 21 / 1327 | time 6[s] | perplexity 3133.47\n",
      "| epoch 1 |  iter 41 / 1327 | time 13[s] | perplexity 1200.75\n",
      "| epoch 1 |  iter 61 / 1327 | time 21[s] | perplexity 975.10\n",
      "| epoch 1 |  iter 81 / 1327 | time 28[s] | perplexity 805.50\n",
      "| epoch 1 |  iter 101 / 1327 | time 36[s] | perplexity 662.09\n",
      "| epoch 1 |  iter 121 / 1327 | time 45[s] | perplexity 642.76\n",
      "| epoch 1 |  iter 141 / 1327 | time 53[s] | perplexity 592.91\n",
      "| epoch 1 |  iter 161 / 1327 | time 61[s] | perplexity 594.51\n",
      "| epoch 1 |  iter 181 / 1327 | time 69[s] | perplexity 585.68\n",
      "| epoch 1 |  iter 201 / 1327 | time 78[s] | perplexity 505.94\n",
      "| epoch 1 |  iter 221 / 1327 | time 86[s] | perplexity 491.61\n",
      "| epoch 1 |  iter 241 / 1327 | time 94[s] | perplexity 442.68\n",
      "| epoch 1 |  iter 261 / 1327 | time 103[s] | perplexity 457.40\n",
      "| epoch 1 |  iter 281 / 1327 | time 111[s] | perplexity 447.76\n",
      "| epoch 1 |  iter 301 / 1327 | time 119[s] | perplexity 383.91\n",
      "| epoch 1 |  iter 321 / 1327 | time 128[s] | perplexity 348.86\n",
      "| epoch 1 |  iter 341 / 1327 | time 136[s] | perplexity 396.43\n",
      "| epoch 1 |  iter 361 / 1327 | time 144[s] | perplexity 400.17\n",
      "| epoch 1 |  iter 381 / 1327 | time 153[s] | perplexity 331.75\n",
      "| epoch 1 |  iter 401 / 1327 | time 161[s] | perplexity 348.20\n",
      "| epoch 1 |  iter 421 / 1327 | time 169[s] | perplexity 339.17\n",
      "| epoch 1 |  iter 441 / 1327 | time 177[s] | perplexity 333.33\n",
      "| epoch 1 |  iter 461 / 1327 | time 186[s] | perplexity 326.08\n",
      "| epoch 1 |  iter 481 / 1327 | time 194[s] | perplexity 303.94\n",
      "| epoch 1 |  iter 501 / 1327 | time 202[s] | perplexity 314.58\n",
      "| epoch 1 |  iter 521 / 1327 | time 211[s] | perplexity 300.86\n",
      "| epoch 1 |  iter 541 / 1327 | time 219[s] | perplexity 318.10\n",
      "| epoch 1 |  iter 561 / 1327 | time 227[s] | perplexity 287.05\n",
      "| epoch 1 |  iter 581 / 1327 | time 235[s] | perplexity 258.28\n",
      "| epoch 1 |  iter 601 / 1327 | time 244[s] | perplexity 337.65\n",
      "| epoch 1 |  iter 621 / 1327 | time 252[s] | perplexity 312.64\n",
      "| epoch 1 |  iter 641 / 1327 | time 261[s] | perplexity 283.40\n",
      "| epoch 1 |  iter 661 / 1327 | time 269[s] | perplexity 268.42\n",
      "| epoch 1 |  iter 681 / 1327 | time 278[s] | perplexity 229.63\n",
      "| epoch 1 |  iter 701 / 1327 | time 286[s] | perplexity 251.80\n",
      "| epoch 1 |  iter 721 / 1327 | time 294[s] | perplexity 262.10\n",
      "| epoch 1 |  iter 741 / 1327 | time 302[s] | perplexity 223.14\n",
      "| epoch 1 |  iter 761 / 1327 | time 311[s] | perplexity 233.95\n",
      "| epoch 1 |  iter 781 / 1327 | time 319[s] | perplexity 218.04\n",
      "| epoch 1 |  iter 801 / 1327 | time 327[s] | perplexity 242.43\n",
      "| epoch 1 |  iter 821 / 1327 | time 336[s] | perplexity 226.93\n",
      "| epoch 1 |  iter 841 / 1327 | time 344[s] | perplexity 230.12\n",
      "| epoch 1 |  iter 861 / 1327 | time 352[s] | perplexity 223.84\n",
      "| epoch 1 |  iter 881 / 1327 | time 361[s] | perplexity 207.33\n",
      "| epoch 1 |  iter 901 / 1327 | time 369[s] | perplexity 256.56\n",
      "| epoch 1 |  iter 921 / 1327 | time 377[s] | perplexity 230.21\n",
      "| epoch 1 |  iter 941 / 1327 | time 385[s] | perplexity 231.79\n",
      "| epoch 1 |  iter 961 / 1327 | time 394[s] | perplexity 246.89\n",
      "| epoch 1 |  iter 981 / 1327 | time 402[s] | perplexity 231.34\n",
      "| epoch 1 |  iter 1001 / 1327 | time 410[s] | perplexity 193.90\n",
      "| epoch 1 |  iter 1021 / 1327 | time 418[s] | perplexity 227.30\n",
      "| epoch 1 |  iter 1041 / 1327 | time 427[s] | perplexity 208.77\n",
      "| epoch 1 |  iter 1061 / 1327 | time 436[s] | perplexity 199.34\n",
      "| epoch 1 |  iter 1081 / 1327 | time 444[s] | perplexity 171.24\n",
      "| epoch 1 |  iter 1101 / 1327 | time 453[s] | perplexity 195.55\n",
      "| epoch 1 |  iter 1121 / 1327 | time 461[s] | perplexity 230.08\n",
      "| epoch 1 |  iter 1141 / 1327 | time 469[s] | perplexity 208.82\n",
      "| epoch 1 |  iter 1161 / 1327 | time 477[s] | perplexity 199.41\n",
      "| epoch 1 |  iter 1181 / 1327 | time 486[s] | perplexity 189.44\n",
      "| epoch 1 |  iter 1201 / 1327 | time 494[s] | perplexity 164.39\n",
      "| epoch 1 |  iter 1221 / 1327 | time 502[s] | perplexity 161.92\n",
      "| epoch 1 |  iter 1241 / 1327 | time 511[s] | perplexity 188.65\n",
      "| epoch 1 |  iter 1261 / 1327 | time 520[s] | perplexity 172.30\n",
      "| epoch 1 |  iter 1281 / 1327 | time 534[s] | perplexity 180.04\n",
      "| epoch 1 |  iter 1301 / 1327 | time 542[s] | perplexity 223.47\n",
      "| epoch 1 |  iter 1321 / 1327 | time 551[s] | perplexity 213.30\n",
      "| epoch 2 |  iter 1 / 1327 | time 554[s] | perplexity 224.35\n",
      "| epoch 2 |  iter 21 / 1327 | time 562[s] | perplexity 206.88\n",
      "| epoch 2 |  iter 41 / 1327 | time 570[s] | perplexity 191.36\n",
      "| epoch 2 |  iter 61 / 1327 | time 579[s] | perplexity 177.55\n",
      "| epoch 2 |  iter 81 / 1327 | time 587[s] | perplexity 162.00\n",
      "| epoch 2 |  iter 101 / 1327 | time 595[s] | perplexity 154.38\n",
      "| epoch 2 |  iter 121 / 1327 | time 603[s] | perplexity 162.93\n",
      "| epoch 2 |  iter 141 / 1327 | time 612[s] | perplexity 180.06\n",
      "| epoch 2 |  iter 161 / 1327 | time 620[s] | perplexity 193.72\n",
      "| epoch 2 |  iter 181 / 1327 | time 628[s] | perplexity 203.36\n",
      "| epoch 2 |  iter 201 / 1327 | time 637[s] | perplexity 186.16\n",
      "| epoch 2 |  iter 221 / 1327 | time 645[s] | perplexity 185.19\n",
      "| epoch 2 |  iter 241 / 1327 | time 653[s] | perplexity 176.96\n",
      "| epoch 2 |  iter 261 / 1327 | time 661[s] | perplexity 187.28\n",
      "| epoch 2 |  iter 281 / 1327 | time 670[s] | perplexity 185.84\n",
      "| epoch 2 |  iter 301 / 1327 | time 678[s] | perplexity 168.25\n",
      "| epoch 2 |  iter 321 / 1327 | time 686[s] | perplexity 140.32\n",
      "| epoch 2 |  iter 341 / 1327 | time 694[s] | perplexity 172.83\n",
      "| epoch 2 |  iter 361 / 1327 | time 703[s] | perplexity 199.62\n",
      "| epoch 2 |  iter 381 / 1327 | time 711[s] | perplexity 155.44\n",
      "| epoch 2 |  iter 401 / 1327 | time 719[s] | perplexity 170.04\n",
      "| epoch 2 |  iter 421 / 1327 | time 727[s] | perplexity 159.10\n",
      "| epoch 2 |  iter 441 / 1327 | time 736[s] | perplexity 164.47\n",
      "| epoch 2 |  iter 461 / 1327 | time 744[s] | perplexity 159.34\n",
      "| epoch 2 |  iter 481 / 1327 | time 753[s] | perplexity 158.38\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9590f981b900>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# 勾配クリッピングを適用して学習\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m trainer.fit(xs, ts, max_epoch, batch_size, time_size, max_grad,\n\u001b[0;32m---> 33\u001b[0;31m             eval_interval=20)\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mylim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Development/etest/zero-dl-nlp/mycode/common/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, xs, ts, max_epoch, batch_size, time_size, max_grad, eval_interval)\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0;31m# 勾配を求め、パラメータを更新\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_duplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 共有された重みを1つに集約\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmax_grad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Development/etest/zero-dl-nlp/mycode/ch06/rnnlm.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, dout)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Development/etest/zero-dl-nlp/mycode/common/time_layers.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, dout)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0mdx\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mdout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0mdx\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         \u001b[0mdx\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# ignore_labelに該当するデータは勾配を0にする\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0mdx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.optimizer import SGD\n",
    "from common.trainer import RnnlmTrainer\n",
    "from common.util import eval_perplexity\n",
    "from dataset import ptb\n",
    "from rnnlm import Rnnlm\n",
    "\n",
    "\n",
    "# ハイパーパラメータの設定\n",
    "batch_size = 20\n",
    "wordvec_size = 100\n",
    "hidden_size = 100  # RNNの隠れ状態ベクトルの要素数\n",
    "time_size = 35  # RNNを展開するサイズ\n",
    "lr = 20.0\n",
    "max_epoch = 4\n",
    "max_grad = 0.25\n",
    "\n",
    "# 学習データの読み込み\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_test, _, _ = ptb.load_data('test')\n",
    "vocab_size = len(word_to_id)\n",
    "xs = corpus[:-1]\n",
    "ts = corpus[1:]\n",
    "\n",
    "# モデルの生成\n",
    "model = Rnnlm(vocab_size, wordvec_size, hidden_size)\n",
    "optimizer = SGD(lr)\n",
    "trainer = RnnlmTrainer(model, optimizer)\n",
    "\n",
    "# 勾配クリッピングを適用して学習\n",
    "trainer.fit(xs, ts, max_epoch, batch_size, time_size, max_grad,\n",
    "            eval_interval=20)\n",
    "trainer.plot(ylim=(0, 500))\n",
    "\n",
    "# テストデータで評価\n",
    "model.reset_state()\n",
    "ppl_test = eval_perplexity(model, corpus_test)\n",
    "print('test perplexity: ', ppl_test)\n",
    "\n",
    "# パラメータの保存\n",
    "model.save_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
